{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 9"
      ],
      "metadata": {
        "id": "rknsqbP9OKjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1."
      ],
      "metadata": {
        "id": "RkY6DLGCOS--"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxrsEPWDOB6X",
        "outputId": "dc2d7d99-f7b8-443c-9c3e-7c127044e024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentences:\n",
            "- Technology has transformed the way we live and work.\n",
            "- From smartphones to smart homes, \n",
            "innovation drives modern life.\n",
            "- Artificial intelligence is revolutionizing industries, making tasks \n",
            "faster and more efficient.\n",
            "- The internet connects people globally, allowing instant communication and \n",
            "access to information.\n",
            "- Technology continues to evolve rapidly, shaping the future of humanity.\n",
            "\n",
            "Filtered Words (after removing stopwords and punctuation):\n",
            "['technology', 'transformed', 'way', 'live', 'work', 'smartphones', 'smart', 'homes', 'innovation', 'drives', 'modern', 'life', 'artificial', 'intelligence', 'revolutionizing', 'industries', 'making', 'tasks', 'faster', 'efficient', 'internet', 'connects', 'people', 'globally', 'allowing', 'instant', 'communication', 'access', 'information', 'technology', 'continues', 'evolve', 'rapidly', 'shaping', 'future', 'humanity']\n",
            "\n",
            "Word Frequency Distribution:\n",
            "technology: 2\n",
            "transformed: 1\n",
            "way: 1\n",
            "live: 1\n",
            "work: 1\n",
            "smartphones: 1\n",
            "smart: 1\n",
            "homes: 1\n",
            "innovation: 1\n",
            "drives: 1\n",
            "modern: 1\n",
            "life: 1\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "revolutionizing: 1\n",
            "industries: 1\n",
            "making: 1\n",
            "tasks: 1\n",
            "faster: 1\n",
            "efficient: 1\n",
            "internet: 1\n",
            "connects: 1\n",
            "people: 1\n",
            "globally: 1\n",
            "allowing: 1\n",
            "instant: 1\n",
            "communication: 1\n",
            "access: 1\n",
            "information: 1\n",
            "continues: 1\n",
            "evolve: 1\n",
            "rapidly: 1\n",
            "shaping: 1\n",
            "future: 1\n",
            "humanity: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Step 0: Install and download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Step 1: Import libraries\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import string\n",
        "\n",
        "# Step 2: Input paragraph (about your favorite topic)\n",
        "paragraph = \"\"\"Technology has transformed the way we live and work. From smartphones to smart homes,\n",
        "innovation drives modern life. Artificial intelligence is revolutionizing industries, making tasks\n",
        "faster and more efficient. The internet connects people globally, allowing instant communication and\n",
        "access to information. Technology continues to evolve rapidly, shaping the future of humanity.\"\"\"\n",
        "\n",
        "# Step 3: Convert to lowercase and remove punctuation\n",
        "lower_nopunct = paragraph.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# Step 4: Tokenize into words and sentences\n",
        "words = word_tokenize(lower_nopunct)\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "# Step 5: Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "# Step 6: Display word frequency distribution\n",
        "fdist = FreqDist(filtered_words)\n",
        "\n",
        "# Output\n",
        "print(\"Sentences:\")\n",
        "for s in sentences:\n",
        "    print(\"-\", s)\n",
        "\n",
        "print(\"\\nFiltered Words (after removing stopwords and punctuation):\")\n",
        "print(filtered_words)\n",
        "\n",
        "print(\"\\nWord Frequency Distribution:\")\n",
        "for word, freq in fdist.items():\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2."
      ],
      "metadata": {
        "id": "xuKKOWpYOItM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Install and download required NLTK data\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Step 1: Initialize stemmers and lemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Step 2: Use filtered_words from Question 1\n",
        "# If you didn't run Q1 in the same notebook, you can reuse this list here:\n",
        "filtered_words = ['technology', 'transformed', 'way', 'live', 'work', 'smartphones', 'smart',\n",
        "                  'homes', 'innovation', 'drives', 'modern', 'life', 'artificial',\n",
        "                  'intelligence', 'revolutionizing', 'industries', 'making', 'tasks',\n",
        "                  'faster', 'efficient', 'internet', 'connects', 'people', 'globally',\n",
        "                  'allowing', 'instant', 'communication', 'access', 'information',\n",
        "                  'continues', 'evolve', 'rapidly', 'shaping', 'future', 'humanity']\n",
        "\n",
        "# Step 3: Apply Stemming and Lemmatization\n",
        "print(f\"{'Word':<20}{'PorterStemmer':<20}{'LancasterStemmer':<20}{'Lemmatizer':<20}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for word in filtered_words:\n",
        "    porter_stem = porter.stem(word)\n",
        "    lancaster_stem = lancaster.stem(word)\n",
        "    lemma = lemmatizer.lemmatize(word)  # Default pos='n' (noun)\n",
        "    print(f\"{word:<20}{porter_stem:<20}{lancaster_stem:<20}{lemma:<20}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHmE_PkdO9WH",
        "outputId": "ccd50f71-a802-43e6-8753-71143b61147e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                PorterStemmer       LancasterStemmer    Lemmatizer          \n",
            "--------------------------------------------------------------------------------\n",
            "technology          technolog           technolog           technology          \n",
            "transformed         transform           transform           transformed         \n",
            "way                 way                 way                 way                 \n",
            "live                live                liv                 live                \n",
            "work                work                work                work                \n",
            "smartphones         smartphon           smartphon           smartphones         \n",
            "smart               smart               smart               smart               \n",
            "homes               home                hom                 home                \n",
            "innovation          innov               innov               innovation          \n",
            "drives              drive               driv                drive               \n",
            "modern              modern              modern              modern              \n",
            "life                life                lif                 life                \n",
            "artificial          artifici            art                 artificial          \n",
            "intelligence        intellig            intellig            intelligence        \n",
            "revolutionizing     revolution          revolv              revolutionizing     \n",
            "industries          industri            industry            industry            \n",
            "making              make                mak                 making              \n",
            "tasks               task                task                task                \n",
            "faster              faster              fast                faster              \n",
            "efficient           effici              efficy              efficient           \n",
            "internet            internet            internet            internet            \n",
            "connects            connect             connect             connects            \n",
            "people              peopl               peopl               people              \n",
            "globally            global              glob                globally            \n",
            "allowing            allow               allow               allowing            \n",
            "instant             instant             inst                instant             \n",
            "communication       commun              commun              communication       \n",
            "access              access              access              access              \n",
            "information         inform              inform              information         \n",
            "continues           continu             continu             continues           \n",
            "evolve              evolv               evolv               evolve              \n",
            "rapidly             rapidli             rapid               rapidly             \n",
            "shaping             shape               shap                shaping             \n",
            "future              futur               fut                 future              \n",
            "humanity            human               hum                 humanity            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3."
      ],
      "metadata": {
        "id": "2e5z8cAeQvR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Original paragraph from Q1\n",
        "paragraph = \"\"\"Technology has transformed the way we live and work. From smartphones to smart homes,\n",
        "innovation drives modern life. Artificial intelligence is revolutionizing industries, making tasks\n",
        "faster and more efficient. The internet connects people globally, allowing instant communication and\n",
        "access to information. Technology continues to evolve rapidly, shaping the future of humanity.\"\"\"\n",
        "\n",
        "# --- 2a. Extract all words with more than 5 letters ---\n",
        "words_more_than_5 = re.findall(r'\\b\\w{6,}\\b', paragraph)\n",
        "\n",
        "# --- 2b. Extract all numbers ---\n",
        "numbers = re.findall(r'\\b\\d+\\b', paragraph)\n",
        "\n",
        "# --- 2c. Extract all capitalized words ---\n",
        "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', paragraph)\n",
        "\n",
        "# --- 3a. Split text into alphabetic-only words (no digits or special chars) ---\n",
        "alphabetic_words = re.findall(r'\\b[a-zA-Z]+\\b', paragraph)\n",
        "\n",
        "# --- 3b. Extract words starting with a vowel (case insensitive) ---\n",
        "vowel_words = re.findall(r'\\b[aeiouAEIOU][a-zA-Z]*\\b', paragraph)\n",
        "\n",
        "# --- Display results ---\n",
        "print(\"Words with more than 5 letters:\\n\", words_more_than_5)\n",
        "print(\"\\nNumbers in text:\\n\", numbers)\n",
        "print(\"\\nCapitalized words:\\n\", capitalized_words)\n",
        "print(\"\\nAlphabetic-only words:\\n\", alphabetic_words)\n",
        "print(\"\\nWords starting with a vowel:\\n\", vowel_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozYeaVMNQUW0",
        "outputId": "d5d1a45b-ab05-4c7c-ed91-ca15944fdf38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with more than 5 letters:\n",
            " ['Technology', 'transformed', 'smartphones', 'innovation', 'drives', 'modern', 'Artificial', 'intelligence', 'revolutionizing', 'industries', 'making', 'faster', 'efficient', 'internet', 'connects', 'people', 'globally', 'allowing', 'instant', 'communication', 'access', 'information', 'Technology', 'continues', 'evolve', 'rapidly', 'shaping', 'future', 'humanity']\n",
            "\n",
            "Numbers in text:\n",
            " []\n",
            "\n",
            "Capitalized words:\n",
            " ['Technology', 'From', 'Artificial', 'The', 'Technology']\n",
            "\n",
            "Alphabetic-only words:\n",
            " ['Technology', 'has', 'transformed', 'the', 'way', 'we', 'live', 'and', 'work', 'From', 'smartphones', 'to', 'smart', 'homes', 'innovation', 'drives', 'modern', 'life', 'Artificial', 'intelligence', 'is', 'revolutionizing', 'industries', 'making', 'tasks', 'faster', 'and', 'more', 'efficient', 'The', 'internet', 'connects', 'people', 'globally', 'allowing', 'instant', 'communication', 'and', 'access', 'to', 'information', 'Technology', 'continues', 'to', 'evolve', 'rapidly', 'shaping', 'the', 'future', 'of', 'humanity']\n",
            "\n",
            "Words starting with a vowel:\n",
            " ['and', 'innovation', 'Artificial', 'intelligence', 'is', 'industries', 'and', 'efficient', 'internet', 'allowing', 'instant', 'and', 'access', 'information', 'evolve', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4."
      ],
      "metadata": {
        "id": "kUVCnlfQQxYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "Contact us at support@example.com or visit our website https://www.example.com.\n",
        "Call us at 123-456-7890 or +91 9876543210 for more info.\n",
        "This isn't a drill – state-of-the-art devices cost about 3.14 times more now!\n",
        "\"\"\"\n",
        "\n",
        "# Step 1: Regex substitutions\n",
        "def regex_substitutions(text):\n",
        "    text = re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', '<EMAIL>', text)               # Email\n",
        "    text = re.sub(r'https?://[^\\s]+', '<URL>', text)                            # URL\n",
        "    text = re.sub(r'\\b(?:\\+91\\s?)?\\d{10}\\b|\\d{3}-\\d{3}-\\d{4}', '<PHONE>', text)  # Phone numbers\n",
        "    return text\n",
        "\n",
        "# Step 2: Custom tokenization\n",
        "def custom_tokenizer(text):\n",
        "    pattern = r\"\"\"\n",
        "        \\b\\w+(?:-\\w+)+\\b          # Hyphenated words\n",
        "        | \\b\\d+\\.\\d+\\b            # Decimal numbers\n",
        "        | \\b\\w+'\\w+\\b             # Contractions\n",
        "        | \\b\\w+\\b                 # Normal words\n",
        "    \"\"\"\n",
        "    return re.findall(pattern, text, re.VERBOSE)\n",
        "\n",
        "# Apply substitutions\n",
        "clean_text = regex_substitutions(text)\n",
        "\n",
        "# Apply tokenization\n",
        "tokens = custom_tokenizer(clean_text)\n",
        "\n",
        "# Display output\n",
        "print(\"Cleaned Text:\\n\", clean_text)\n",
        "print(\"\\nCustom Tokens:\\n\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWfoFeqBQxzp",
        "outputId": "4ce01125-6bac-4720-ae58-b17eb2ffaa63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " \n",
            "Contact us at <EMAIL> or visit our website <URL>\n",
            "Call us at <PHONE> or +91 <PHONE> for more info.\n",
            "This isn't a drill – state-of-the-art devices cost about 3.14 times more now!\n",
            "\n",
            "\n",
            "Custom Tokens:\n",
            " ['Contact', 'us', 'at', 'EMAIL', 'or', 'visit', 'our', 'website', 'URL', 'Call', 'us', 'at', 'PHONE', 'or', '91', 'PHONE', 'for', 'more', 'info', 'This', \"isn't\", 'a', 'drill', 'state-of-the-art', 'devices', 'cost', 'about', '3.14', 'times', 'more', 'now']\n"
          ]
        }
      ]
    }
  ]
}